{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://doity.com.br/media/doity/eventos/evento-20025-logo_organizador.png)\n",
    "\n",
    "# Prova de Descoberta do Conhecimento\n",
    "\n",
    "* **Prof. Cleilton Lima Rocha**\n",
    "* **emails:** climarocha@gmail.com\n",
    "* **deadline: 20/5 às 12h**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este projeto exploraremos os dados Call_Data disponível disponível na pasta.\n",
    "\n",
    "\n",
    "Para facilitar a administração da segurança pública, o Departamento de Polícia de Seattle dividiu a cidade em 5 partes, cada uma com uma delegacia. Cada delegacia foi subdividida em setores, e estes foram divididos em beats (hondas). A administração tem um dataset chamado Call_Data, para obter maiores informações acesse este [link](https://data.seattle.gov/Public-Safety/Call-Data/33kz-ixgy).\n",
    "\n",
    "O objetivo do nosso projeto é apoiar os policiais quanto as medidas prescritivas que eles devem tomar ao tentarem resolver uma chamada. Para isto eles têm disponível o histórico de tudo o que já foi resolvido, por ele e por seus colegas, e sua solução de Data Science capaz de prever a variável alvo da nossa prova será **Event Clearance Description**.\n",
    "\n",
    "Boa prova e hands on!\n",
    "\n",
    "**PS.:**\n",
    "* Quando houver necessidade de splitar os dados aplique a proporção 70 para treino e 30 para teste\n",
    "* Quando houver necessidade de utilizar o random_state defina o valor 100\n",
    "* O título do email deve ser \"Prova KDD - Turma 2 - [Membros da equipe]\"\n",
    "* Envie o código fonte e o report (File ==> Download As ==> Html ou PDF), com o nome dos membros da dupla, para um dos meus emails, climarocha@gmail.com até o dia **20/5 às 12h**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questões\n",
    "\n",
    " * **1. Importe o data set train_call_data e considere a variável alvo 'Event Clearance Description'(0,5 pontos)** \n",
    "     * **1.1. Como está o balanceamento das classes?**\n",
    "     * **P.S.: Não é obrigatório aplicar o undersampling and oversampling sobre o dataset**. \n",
    "     * **P.S.: Você pode usar qualquer um dos datasets de treinamento a v1 ou a v2**. \n",
    " * **2. Realize o EDA que você julgar necessário (análise exploratória dos dados), o objetivo do EDA é mostrar alguns insights sobre os dados (1,0 pontos)**\n",
    "     * *Utilize recursos visuais, por exemplo gráficos* \n",
    " * **3. Realize o tratamento que você julgar mais adequado aos dados. (2,0 pontos)**\n",
    "     * *P.S.: Explique, com suas palavras, porque o processo de feature engineering é necessário*\n",
    "     * *P.S.: A criação de um pipeline lhe dará pontos extras e melhorará o reaproveitamento de código *\n",
    " * **4. Selecione duas soluções candidatas e justifique suas escolhas. Mostre os pontos negativos e positivos de cada modelo. (2,0 pontos)**\n",
    " * **5. Construa os modelos de aprendizagem de máquina para cada modelo (2,0 ponto)**    \n",
    " * **6. Para cada modelo aplique uma combinação aos hiperparâmetros com o GridSearch e aplique também o CrossValidation (2,0 pontos)**\n",
    "     * P.S.: Explique, com suas palavras, a necessidade de utilizar GridSearch e CrossValidation\n",
    "     * P.S.: Explique a importância para de no mínimo um hiperparâmetro para cada modelo\n",
    " * **7. Defina uma métrica de avaliação e avalie as soluções candidatas. Justifique a escolha da sua métrica. (1,0 ponto)**\n",
    " * **8. Escolha um dos modelos, por exemplo o melhor modelo, e faça uma análise do overfitting e underfitting. Justique sua resposta com base em experimentos. (1,5 pontos)**\n",
    "     * *Analise no mínimo 2 hiperparâmetros e também o número de amostras utilizado no treinamento* \n",
    "     * *Utilize recursos visuais, por exemplo gráficos, se você achar neccessário* \n",
    " * **9. Realize a predição sobre os dado test_call_data, como o seu modelo saiu? (1,0 ponto)**\n",
    " * **10. Se seu modelo permitir analisar a importância das features, analise-o e tente justificar de forma subjetiva a importância da feature. Por exemplo, a feature_chamadas_a_noite possui um alto coeficiente, pois há uma tendência dos crimes acontecerem a noite, não tão simples assim :P. (1,0 ponto)**\n",
    " * **11. Aplique clusterização, preferencialmente o KMeans sobre o dado, e comunique suas novas descobertas, sinta-se a vontade para apresentar uma solução com recursos visuais (2,0 pontos)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bom trabalho!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
